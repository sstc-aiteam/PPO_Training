accelerator_kwargs/step_scheduler_with_optimizer: false
adap_kl_ctrl: true
backward_batch_size: 4
batch_size: 4
cliprange: 0.2
cliprange_value: 0.2
compare_steps: 1
early_stopping: false
exp_name: train
forward_batch_size: null
gamma: 1
global_backward_batch_size: 8
global_batch_size: 8
gradient_accumulation_steps: 2
horizon: 10000
init_kl_coef: 0.2
is_encoder_decoder: false
is_peft_model: true
kl_penalty: kl
lam: 0.95
learning_rate: 5.0e-06
log_with: tensorboard
max_grad_norm: 1.0
mini_batch_size: 2
model_name: /home/itrib30156/llm_vision/qwen3b
optimize_cuda_cache: null
optimize_device_cache: true
ppo_epochs: 4
project_kwargs/logging_dir: /home/itrib30156/llm_vision/LLaMA-Factory/logs/ppo_training_continued_fixed
query_dataset: imdb
ratio_threshold: 10.0
remove_unused_columns: true
reward_model: sentiment-analysis:lvwerra/distilbert-imdb
score_clip: null
seed: 42
steps: 20000
target: 6.0
target_kl: 1
task_name: null
total_ppo_epochs: 5000
tracker_project_name: trl
use_score_norm: false
use_score_scaling: false
vf_coef: 0.1
whiten_rewards: false
world_size: 2
